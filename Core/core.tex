%*******************************************************************************
%*********************************** First Introduction *****************************
%*******************************************************************************
%\chapter{Introduction}  %Title of the First Introduction
%\chapter*{Introduction}
\chapter{Core}  %Title of the First Introduction
%\addcontentsline{tableofcontents}{chapter}{introduction}

\ifpdf
    \graphicspath{{Core/Figs/Raster/}{Core/Figs/PDF/}{Core/Figs/}}
\else
    \graphicspath{{Core/Figs/Vector/}{Core/Figs/}}
\fi

%********************************** %First Section  **************************************
\section{Data Collection} %Section - 1.1 
Our dataset is the Variome Corpus\cite{verspoor2013annotating}, which is openly accessible. \footnote{\href{http://www.opennicta.com.au/home/health/variome}\url{http://www.opennicta.com.au/home/health/variome}} \citet{verspoor2013annotating} gave a detailed illustration of the document selection and annotation process. I will summarize the main points here.
\subsection{Background}
A major part of the current biomedical research lies in understanding the relations between human genetic variation and disease phenotypes. The \emph{Human Variome Project}, or \emph{HVP}, is a global initiative to collect all genetic variation information affecting human health\cite{ring2006human}. In particular, it acts as a liaison between individuals and organizations to integrate the genetic variants into databases that are open to the general public\cite{verspoor2013annotating}. The \emph{International Society for Gastrointestinal Hereditary Tumours (InSiGHT)}, is an international organization which aims to benefit patients with hereditary gastrointestinal(GI) tumours by research, education and personal assistance. In 2008, InSiGHT and HVP began a collaboration which propels InSiGHT to refine its process in the integration and interpretation of genetic variants. Consequently, a substantial effort was made to understand the mutation of mismatch repair(MMR) genes, the cause of Lynch Syndrome - one of the main syndromes of GI cancer\cite{silva2009mismatch}. A total of 10 full-text articles were selected from PubMed Central\textregistered  by searching the common Lynch syndrome genes. These documents are mostly about inherited colon cancer. The annotation schema, also known as the Variome Annotation Schema\cite{verspoor2013annotating}, include 11 entity types and 13 relation types. as can be seen in the table here
\begin{table}
	\caption{A nice looking table}
	\centering
	\label{table:nice_table}
	\begin{tabular}{l c c c c}
		\hline 
		\multirow{2}{*}{Dental measurement} & \multicolumn{2}{c}{Species I} & \multicolumn{2}{c}{Species II} \\ 
		\cline{2-5}
		& mean & SD  & mean & SD  \\ 
		\hline
		I1MD & 6.23 & 0.91 & 5.2  & 0.7  \\
		
		I1LL & 7.48 & 0.56 & 8.7  & 0.71 \\
		
		I2MD & 3.99 & 0.63 & 4.22 & 0.54 \\
		
		I2LL & 6.81 & 0.02 & 6.66 & 0.01 \\
		
		CMD & 13.47 & 0.09 & 10.55 & 0.05 \\
		
		CBL & 11.88 & 0.05 & 13.11 & 0.04\\ 
		\hline 
	\end{tabular}
\end{table}

In short, the corpus is Inspired by needs of inSIGHT database, but intended for broader applications. Documents relevant to the genetics of Lynch syndrome, which covers inherited colon cancer as well as certain other cancers. Selected with PubMed Central To train tools for mining genetic variation and its relationship to disease
Here in this information extraction task, we treat the manually annotated data as the \emph{gold data}, 
\section{Dependency Graph and Shortest Path}
	\begin{figure}
		\centering
			\includegraphics[width=\textwidth]{Dependency_Graph}
			\caption{Dependency Graph of `` The p.Lys618Ala variant was co-existent with pathogenic mutations in two unrelated LS families.''}
			\label{fig:Dependency_Graph}   
	\end{figure}

The dependency graph of a sentence is a directed graph, where nodes represent sentence tokens, and edges indicate their semantic relations. Figure \ref{fig:Dependency_Graph} shows the dependency graph of the sentence \emph{`` The p.Lys618Ala variant was co-existent with pathogenic mutations in two unrelated LS families.''} generated by the Stanford Parser. Such a graph preserves the rich semantic structure of a sentence, and has been widely regarded as an informative way of presenting a sentence. A detailed explanation of the relative constituents in the graph can be found in \cite{de2008stanford}. However, the point is to transfer only human-readable sentences to a computer-understandable data structure. The general idea would be to feed this graph into a learning algorithm and classify relations based on similarity to the sentence graph in the training set. Different approaches exist for this process. Turku Event Extraction System (TEES)\footnote{https://github.com/jbjorne/TEES}, for instance, engineers a feature vector which consists of token features(part-of-speech tags and character constituents for each word), sentence features(bag-of-words counts), and graph-based features(dependency path represented as N-grams) and builds a multi-class SVM model with the feature vector\cite{bjorne2011generalizing}. In this project, we decide to use the \emph{Shortest Path Hypothesis}\cite{bunescu2005shortest}, namely the heuristic that the relation between two entities in a sentence can be distilled from the shortest path between these entities in the undirected version of the sentence dependency graph. This effectively reduces the burden of feature engineering\cite{liu2013approximate}, but it also calls for high-quality training data. We believe that with effective parameter tuning and clever graph matching techniques, the shortest path can be a single standalone feature for a relation between two entities.
\section{Approximate Subgraph Matching Algorithm}
\textbf{Disclaimer: As the system was designed for event extraction, it is more convenient to refer the system as being learning "events", while in essence events are nothing more than complex relations between entities. This is exactly the rationale behind adapting an event extraction system for relations extraction. What was later done in the adaptation process was treating relation as a type of "event". So "relations" and "events" are used (somewhat) interchangeably below. }\newline
The Approximate Subgraph Matching framework, proposed by \citet{liu2013approximate} has the following work flow:
\subsection{Prepossessing}
To separate Named Entity Recognition from Relation Extraction problem, the named entity annotations are provided in training, development and test sets. Effectively, this is just asking computer to extract possible relations between these entities without worrying how to recognize them accurately. Of course, named entity recognition is an important step in a real relation extraction task as cite cite, because biological named entity recognition is such a complex problem and sometimes the relation extraction success would depend on the accuracy of NER.

the performance of the subgraph matching method, as an instance-based learning strategy (Alpaydin, 2004), is dependent on having good training examples that express the events in a range of syntactic structures, cite
\subsection{Rule Learning}
For each annotated sentence in the training set, a dependency graph is generated and the nodes representing entities are marked. The entity tokens are then replaced with their entity types, such that the rules learned are about an the generic entity types (e.g. gene mutation) instead of specific entities (e.g. p.Lys618Ala), so that our model has a better ability to generalize as we might not see the specific entities again in the test set. Next, the graph is transformed to its undirected version and the shortest path between entities are found with Dijkstra algorithm. This path is leaned as a rule associated with the event type in the annotation as a rule corresponding to that event type. Provided there is enough training data, a set of rules would be learned for each event type, representing the graph patterns that indicating a specific type of event. 
\subsection{Sentence Matching}
The rules generated from the previous step could, in theory, be used to match sentences. For each sentence in the test set, a dependency graph can be generated together with the entity annotations(these are provided, as discussed). The graph can be searched exhaustively looking at the path(s) between each entity tokens, for an exact match with one or more rules within the rule set. This step is know as searching for exact subgraph isomorphism. \newline
The above-mentioned matching approach would invariably lead to low recall, as the richness of language can almost always produce slightly different dependency graph structure representing exactly the same events between the same entities. This leads to the rationale behind approximate subgraph matching, which relaxes the matching process and allows for a penalty-based mismatch. 
\subsection{Rule Optimizing}
To avoid learning the idiosyncrasies in the training data, an iterative rule set optimization process is executed. After the initial learning phase, each rule in the rule set is tested first on the training data to see if it get produce accurate enough predictions (above 0.25). The low performing rules are discarded as a consequence.   
\section{System Adaptation}
As mentioned in \ref{section1.3}, the project aims at adapting an existing system used for event-retrieval tasks on relation extraction tasks.
\subsection{BioNLP Shared Tasks}
BioNLP shared Task series is a community-wide text mining challenge specifically for biomedical literatures. The GE task in shared task 2013 aims at retireving events of the following format:
\begin{table}
	\caption{Events}
	\centering
	\label{table:events}
	\begin{tabular}{l c c c c}
		\hline 
		\multirow{2}{*}{Dental measurement} & \multicolumn{2}{c}{Species I} & \multicolumn{2}{c}{Species II} \\ 
		\cline{2-5}
		& mean & SD  & mean & SD  \\ 
		\hline
		I1MD & 6.23 & 0.91 & 5.2  & 0.7  \\
		
		I1LL & 7.48 & 0.56 & 8.7  & 0.71 \\
		
		I2MD & 3.99 & 0.63 & 4.22 & 0.54 \\
		
		I2LL & 6.81 & 0.02 & 6.66 & 0.01 \\
		
		CMD & 13.47 & 0.09 & 10.55 & 0.05 \\
		
		CBL & 11.88 & 0.05 & 13.11 & 0.04\\ 
		\hline 
	\end{tabular}
\end{table}

The a1 files does (to be added), the a2 files does (to be added), 

\subsection{Variome Annotation Schema}
\begin{table}
	\caption{Overall Result}
	\centering
	\label{table:overall_result}
	\begin{tabular}{|c | c |c  |}
		\hline 
		{Relation Type} 
		& Arg1 & Arg2\\ 
		\hline
		relatedTo  & mutation & disease \\
		relatedTo & disease & gene\\
		relatedTo & disease & body-part\\
		\hline 
		has     & gene & mutation\\
		has     & mutation & size\\
		has     & disease & characteristic\\
		has     & cohort-patient & age\\
		has     & cohort-patient & characteristic\\
		has     & cohort-patient & disease\\
		has     & cohort-patient & ethnicity\\
		has     & cohort-patient & gender\\
		has     & cohort-patient & mutation\\
		has     & cohort-patient & size \\
		\hline 
	\end{tabular}
\end{table}

During the duration of this project, most of my attempts to fully adapt the system to relation extraction tasks have failed. In essence, the differentiation in the retrieval process lies in the event retrieval relies on the detection and prediction of a trigger word, where as the relation extraction does not. 

My only attempts that worked was transforming the annotation format of the Variome Corpus to that of the BioNLP Shared Task 2013, such that the original system would not break. The transformation is illustrated in this tables. The "has" relationship is transformed to "gene regulation" event, and "relatedTo" relationship is transformed to "Phosphyrilation" event, with the entity annotation slightly too. The entities would be of type "Protein" instead of the original entity types in the Variome Corpus. \textbf{The major bottleneck for this adaptation work is that the original system includes a hard-coded trigger detection and prediction process.} As for events detecting trigger words such as "activates" for gene expression is an important step for prediction. However, this process is not included at all in the event prediction process and to cope with the original system I had to add "fake triggers" for these events. \newline
As a result, the first entity of each event/relation annotation is added as the trigger for the notation. 

After this first attempt I had a few better ideas to add fake triggers, the best one being adding the entity types (patient-cohort), with parenthesis directly after the entity tokens and do a binding event. Due to the time constraints and these ideas being essentially fool's gold, I did not implement these ideas. 

The results of my first attempt is shown in .


\section{Results}
\begin{table}
	\caption{Overall Result}
	\centering
	\label{table:overall_result}
	\begin{tabular}{|c | c c |c c c c |}
		\hline 
		{Relation Type} 
		& Gold & Answer  & Match  & Precision & Recall & F1-score\\ 
		\hline
		has  & 1711 & 1310 & 402 & 0.3069 & 0.2350 & 0.2661 \\
		
		relatedTo & 157 & 1498 &  36 & 0.0240 & 0.2293 & 0.0435\\
		\hline 
		TOTAL  & 1868 & 2808 & 438 & 0.1560 & 0.2345 & 0.1874 \\
		\hline 
	\end{tabular}
\end{table}
The overall result of the system is shown in table \ref{table:overall_result}, the main reason the system is not performing well is that it is not predicting the triggers words correctly, because I have chosen to treat entity annotations as triggers.
